---
title: "FASTQ to Counts Matrix Pipeline"
author: "Sourav Roy (s2599932)"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```

# Pre-processing Pipeline for SMART-Seq2 scRNA-seq Data

This document outlines the upstream processing pipeline to convert raw FASTQ files into a gene expression count matrix. Each bash script is designed to be run independently after setting the appropriate paths.

**Note:** Code chunks are set to `eval = FALSE` - copy and run scripts separately in terminal.

## Software Versions

| Tool | Version |
|------|---------|
| FastQC | 0.11.9 |
| MultiQC | 1.22.3 |
| Trimmomatic | 0.39 |
| STAR | 2.7.10a |
| featureCounts | 2.0.3 |

---

## Step 1: Quality Control with FastQC and MultiQC

Run FastQC on all FASTQ files, then aggregate reports with MultiQC.

```{bash}
#!/bin/bash

# Set paths
INPUT_DIR="/path/to/fastq/files"
FASTQC_OUT="$INPUT_DIR/fastqc-results"
MULTIQC_OUT="$INPUT_DIR/multiqc-results"

# Create output directories
mkdir -p "$FASTQC_OUT"
mkdir -p "$MULTIQC_OUT"

# Run FastQC on all fastq files
fastqc -o "$FASTQC_OUT" "$INPUT_DIR"/*.fastq

# Aggregate results with MultiQC
multiqc "$FASTQC_OUT" -o "$MULTIQC_OUT"
```

---

## Step 2: Read Trimming with Trimmomatic (If required)

Trim reads to 50bp using CROP.

```{bash}
#!/bin/bash

# Set paths
INPUT_DIR="/path/to/fastq/files"
OUTPUT_DIR="/path/to/trimmed/output"
TRIMMOMATIC_JAR="/path/to/trimmomatic.jar"

mkdir -p "$OUTPUT_DIR"

# Trim each fastq file
for fastq_file in "$INPUT_DIR"/*.fastq; do
    base_name=$(basename "$fastq_file" .fastq)
    output_file="$OUTPUT_DIR/${base_name}_trimmed.fastq"

    java -jar "$TRIMMOMATIC_JAR" SE -phred33 \
        "$fastq_file" \
        "$output_file" \
        CROP:50

    echo "Trimmed: $base_name"
done
```

---

## Step 3: Download Reference Genome and Annotation

Download human genome (GRCh38) and GTF annotation from Ensembl.

```{bash}
#!/bin/bash

# Set output directory
REF_DIR="/path/to/reference-genome"
mkdir -p "$REF_DIR"
cd "$REF_DIR"

# Download human genome fasta
wget https://ftp.ensembl.org/pub/release-112/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna_sm.primary_assembly.fa.gz

# Download annotation GTF
wget https://ftp.ensembl.org/pub/release-112/gtf/homo_sapiens/Homo_sapiens.GRCh38.112.gtf.gz

# Decompress files
gunzip Homo_sapiens.GRCh38.dna_sm.primary_assembly.fa.gz
gunzip Homo_sapiens.GRCh38.112.gtf.gz
```

---

## Step 4: Generate STAR Genome Index

Build the STAR index for alignment. This step requires significant memory (~32GB).

```{bash}
#!/bin/bash

# Set paths
GENOME_DIR="/path/to/star-index"
GENOME_FASTA="/path/to/reference-genome/Homo_sapiens.GRCh38.dna_sm.primary_assembly.fa"
GTF_FILE="/path/to/reference-genome/Homo_sapiens.GRCh38.112.gtf"
NUM_CORES=8

mkdir -p "$GENOME_DIR"

# Generate STAR index
STAR --runThreadN $NUM_CORES \
     --runMode genomeGenerate \
     --genomeDir "$GENOME_DIR" \
     --genomeFastaFiles "$GENOME_FASTA" \
     --sjdbGTFfile "$GTF_FILE" \
     --sjdbOverhang 49
```

---

## Step 5: Align Reads with STAR

Align trimmed reads to the reference genome.

```{bash}
#!/bin/bash

# Set paths
INPUT_DIR="/path/to/trimmed/fastq"
OUTPUT_DIR="/path/to/aligned/bam"
GENOME_DIR="/path/to/star-index"
NUM_CORES=8

mkdir -p "$OUTPUT_DIR"

# Align each sample
for fastq_file in "$INPUT_DIR"/*.fastq; do
    base_name=$(basename "$fastq_file" .fastq)
    output_prefix="$OUTPUT_DIR/${base_name}_"

    STAR --runThreadN $NUM_CORES \
         --genomeDir "$GENOME_DIR" \
         --readFilesIn "$fastq_file" \
         --outFileNamePrefix "$output_prefix" \
         --outSAMtype BAM SortedByCoordinate

    echo "Aligned: $base_name"
done
```

---

## Step 6: Check Alignment Quality (Optional)

Use samtools flagstat to check alignment statistics.

```{bash}
#!/bin/bash

# Set paths
BAM_DIR="/path/to/aligned/bam"

# Run flagstat on each BAM file
for bam_file in "$BAM_DIR"/*_Aligned.sortedByCoord.out.bam; do
    base_name=$(basename "$bam_file" _Aligned.sortedByCoord.out.bam)
    samtools flagstat "$bam_file" > "$BAM_DIR/${base_name}_flagstat.txt"
done
```

---

## Step 7: Quantify with featureCounts

Count reads mapping to genes using featureCounts.

```{bash}
#!/bin/bash

# Set paths
BAM_DIR="/path/to/aligned/bam"
GTF_FILE="/path/to/reference-genome/Homo_sapiens.GRCh38.112.gtf"
OUTPUT_DIR="/path/to/counts"
NUM_CORES=12

mkdir -p "$OUTPUT_DIR"

# Run featureCounts on all BAM files
featureCounts -T $NUM_CORES \
              -a "$GTF_FILE" \
              -o "$OUTPUT_DIR/unprocessed_counts.txt" \
              "$BAM_DIR"/*_Aligned.sortedByCoord.out.bam
```

---

## Step 8: Clean Count Matrix in R

Process the featureCounts output to create a clean count matrix.

### Load required libraries
```{r}
library(tidyverse)
library(biomaRt)
```

### Read and clean count matrix
```{r}
# Read featureCounts output
counts_raw <- read.table("/path/to/counts/unprocessed_counts.txt",
                         header = TRUE,
                         row.names = 1)

# Clean column names to extract sample IDs (for GEO/SRA data)
cleaned_colnames <- gsub(".*\\.([S|X]RR[0-9]+)_.*", "\\1", colnames(counts_raw))
colnames(counts_raw) <- cleaned_colnames

# Remove featureCounts metadata columns
counts <- counts_raw %>%
  dplyr::select(-all_of(c("Chr", "Start", "End", "Strand", "Length")))
```

### Alternative: Clean for ArrayExpress data
```{r}
# For ArrayExpress data (ERR accessions)
cleaned_colnames <- gsub(".*\\.([E|X]RR[0-9]+)_.*", "\\1", colnames(counts_raw))
colnames(counts_raw) <- cleaned_colnames

counts <- counts_raw %>%
  dplyr::select(-all_of(c("Chr", "Start", "End", "Strand", "Length")))
```

### Save cleaned counts
```{r}
write.csv(counts, file = "/path/to/output/counts.csv", row.names = TRUE)
```

---

## Optional: Gene Annotation and Filtering

### Check for zero-expression genes
```{r}
# Load counts
counts <- read.csv("/path/to/counts.csv", header = TRUE, row.names = 1)

# Find genes with no expression
row_sums <- rowSums(counts)
zero_expression <- rownames(counts)[row_sums == 0]

cat("Genes with zero expression:", length(zero_expression), "\n")
```

### Map Ensembl IDs to gene symbols
```{r}
# Connect to Ensembl
ensembl <- useMart("ensembl", dataset = "hsapiens_gene_ensembl")

# Get gene information
gene_info <- getBM(
  attributes = c("ensembl_gene_id", "external_gene_name", "gene_biotype"),
  filters = "ensembl_gene_id",
  values = rownames(counts),
  mart = ensembl
)
```

### Filter for specific biotypes (e.g., lncRNA)
```{r}
# Get lncRNA genes
lncRNA_genes <- gene_info %>%
  filter(gene_biotype == "lncRNA")

# Subset counts to lncRNA only
lncRNA_counts <- counts[lncRNA_genes$ensembl_gene_id, ]

cat("lncRNA genes:", nrow(lncRNA_counts), "\n")
```

---

## Output

After completing this pipeline, you will have:

1. **FastQC reports** - Quality metrics for each sample
2. **MultiQC report** - Aggregated quality summary
3. **Trimmed FASTQ files** - Quality-filtered reads
4. **BAM files** - Aligned reads
5. **Count matrix** - Gene expression counts (genes Ã— samples)

The count matrix is ready for downstream analysis in R using packages like Seurat, scran, or scater.
