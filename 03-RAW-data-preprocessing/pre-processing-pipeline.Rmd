---
title: "fastq-to-counts"
author: "S2599932"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## This pipeline is to preprocess single cell RNA sequencing data generated using SMART-Seq 2 protocol

## Initial quality control using **FastQC**

```{bash}
for file in /home/s2599932/human-dataset/GSE36552_ENA_RAW/*.fastq
do
  fastqc -o /home/s2599932/human-dataset/GSE36552_ENA_RAW/fastqc-results "$file"
done
```

```{bash}
# Run multiqc to collate all the results
multiqc -o /home/s2599932/human-dataset/GSE36552_ENA_RAW/fastqc-results/multiqc-results /home/s2599932/human-dataset/GSE36552_ENA_RAW/fastqc-results/.
```

### Use **trimmomatic** to trim low quality reads

#### For single end data
```{bash}
#!/bin/bash

# Define input and output directories
INPUT_DIR="/scratch1/s2599932/GSE36552/fastq-files"
OUTPUT_DIR="/scratch1/s2599932/GSE36552/fastq-files/trimmed-reads"

# Define the path to Trimmomatic if not in the PATH
TRIMMOMATIC_PATH="/home/s2599932/Trimmomatic-0.39/trimmomatic-0.39.jar"

# Define the number of cores to use
NUM_CORES=10

# Create output directory if it does not exist
mkdir -p $OUTPUT_DIR

# Function to run Trimmomatic
run_trimmomatic() {
    fastq_file=$1
    base_name=$(basename $fastq_file .fastq)
    output_file="$OUTPUT_DIR/${base_name}_trimmed.fastq"
    
    java -jar $TRIMMOMATIC_PATH SE -phred33 $fastq_file $output_file CROP:50
    
    echo "Trimmed $fastq_file and saved to $output_file"
}

export -f run_trimmomatic
export TRIMMOMATIC_PATH
export OUTPUT_DIR

# Find all FASTQ files and process them in parallel
find $INPUT_DIR -name "*.fastq" | parallel -j $NUM_CORES run_trimmomatic {}

echo "Trimming complete for all files."
```


### Run **FastQC** on the trimmed fastq files

```{bash}
for file in /home/s2599932/human-dataset/GSE36552_ENA_RAW/trimmed-fastq/*.fastq
do
  fastqc -o /home/s2599932/human-dataset/GSE36552_ENA_RAW/trimmed-fastq/trimmed-fastqc-results/ "$file"
done
```

### Run **MultiQC** to collate all the results

```{bash}
multiqc -o /home/s2599932/human-dataset/GSE36552_ENA_RAW/trimmed-fastq/trimmed-fastqc-results/trimmed-multiqc /home/s2599932/human-dataset/GSE36552_ENA_RAW/trimmed-fastq/trimmed-fastqc-results.
```

### Use **STAR** to align the reads to reference genome

```{bash}
# Create the reference genome after downloading the human genome fasta file and annotation .gtf file
STAR --runThreadN 12 \
     --runMode genomeGenerate \
     --genomeDir /scratch1/s2599932/pre-processing/reference-genome/human-genome \
     --genomeFastaFiles /scratch1/s2599932/pre-processing/reference-genome/fasta/Homo_sapiens.GRCh38.dna_sm.primary_assembly.fa \
     --sjdbGTFfile /scratch1/s2599932/pre-processing/reference-genome/gtf/Homo_sapiens.GRCh38.112.gtf \
     --sjdbOverhang 99
```

```{bash}
# Define input and output directories
input_dir="/home/s2599932/human-dataset/GSE36552_ENA_RAW/trimmed-fastq"
output_dir="/home/s2599932/pre-processing/alignment/mapped"
genome_dir="/home/s2599932/pre-processing/alignment/ref"

# Loop over each FASTQ file in the input directory
for fastq_file in ${input_dir}/*.fastq
do
  # Extract the base name of the file (without path and extension)
  base_name=$(basename ${fastq_file} _trimmed.fastq)
  
  # Define the output prefix for this file
  output_prefix="${output_dir}/${base_name}_"

  # Run STAR for the current file
  STAR --runThreadN 12 \
       --genomeDir ${genome_dir} \
       --readFilesIn ${fastq_file} \
       --outFileNamePrefix ${output_prefix} \
       --outSAMtype BAM SortedByCoordinate
done
```


```{bash}
#!/bin/bash

# For paired end dat
# Define input and output directories
input_dir="/scratch1/s2599932/GSE71318/fastq-files"
output_dir="/scratch1/s2599932/GSE71318/fastq-files/mapped-reads"
genome_dir="/home/s2599932/pre-processing/alignment/ref"

# Loop over each _1.fastq file in the input directory
for fastq_file in ${input_dir}/*_1.fastq
do
  # Extract the base name of the file (without path and _1.fastq)
  base_name=$(basename ${fastq_file} _1.fastq)
  
  # Define the matching _2.fastq file
  fastq_file_r2="${input_dir}/${base_name}_2.fastq"

  # Check if the matching _2.fastq file exists
  if [[ -f ${fastq_file_r2} ]]; then
    # Define the output prefix for this file
    output_prefix="${output_dir}/${base_name}_"

    # Run STAR for the current file
    STAR --runThreadN 12 \
         --genomeDir ${genome_dir} \
         --readFilesIn ${fastq_file} ${fastq_file_r2} \
         --outFileNamePrefix ${output_prefix} \
         --outSAMtype BAM SortedByCoordinate
  else
    echo "Matching file for ${fastq_file} not found: ${fastq_file_r2}"
  fi
done

```


### Check the quality of alignment using **samtools** (optional)

```{bash}
# Define the output directory where BAM files are located
output_dir="/home/s2599932/pre-processing/alignment/mapped"

# Loop over each BAM file in the output directory
for bam_file in ${output_dir}/*_Aligned.sortedByCoord.out.bam
do
  # Extract the base name of the file (without path and extension)
  base_name=$(basename ${bam_file} _Aligned.sortedByCoord.out.bam)

  # Define the output file for flagstat results
  flagstat_output="${output_dir}/${base_name}_flagstat.txt"

  # Run samtools flagstat for the current BAM file
  samtools flagstat ${bam_file} > ${flagstat_output}
done
```

### Use **featureCounts** to quantify the aligned reads

> Will generate a single compiled counts file, thats what we need!!

#### For Single End Reads
```{bash}
# Define directories and annotation file
bam_dir="/home/s2599932/pre-processing/alignment/mapped"
gtf_file="/home/s2599932/pre-processing/alignment/fasta/Homo_sapiens.GRCh38.112.gtf"
output_dir="/home/s2599932/pre-processing/alignment/counts"

# Create output directory if it doesn't exist
mkdir -p ${output_dir}

# Collect all BAM files into a single variable
bam_files=$(ls ${bam_dir}/*_Aligned.sortedByCoord.out.bam)

# Define the output file for featureCounts results
counts_output="${output_dir}/all_samples_featureCounts.txt"

# Run featureCounts for all BAM files
featureCounts -T 12 \
              -a ${gtf_file} \
              -o ${counts_output} \
              ${bam_files}
```

### For Paired End reads
```{bash}
# Create output directory if it doesn't exist
mkdir -p ${output_dir}

# Collect all BAM files into a single variable
bam_files=$(ls ${bam_dir}/*_Aligned.sortedByCoord.out.bam)

# Define the output file for featureCounts results
counts_output="${output_dir}/all_samples_featureCounts.txt"

# Run featureCounts for all BAM files with paired-end option
featureCounts -T 12 \
              -p \
              -a ${gtf_file} \
              -o ${counts_output} \
              ${bam_files}

```

### The all_sample_featureCounts.txt must have the count data for every sample along with some additional columns that has to dropped in the downstream analysis.


### Clean the counts matrix in R
```{r}
cleaned_colnames <- gsub(".*\\.([S|X]RR[0-9]+)_.*", "\\1", colnames(t1)) # Just extract the run accession use it as 
colnames(t1) <- cleaned_colnames

t1 <- t1 %>% dplyr::select(-all_of(c("Chr","Start","End","Strand","Length")))
```

```{r}
write.csv(t1, file = "./GSE36552_counts.csv", row.names = TRUE)
```



## Use Rsubread to create counts matrix
```{r}
# Load the Rsubread package
library(Rsubread)

# Define the path to your BAM files and the GTF annotation file
bam_files <- list.files(path = "/scratch1/s2599932/E-MTAB-3929/mapped-reads", pattern = "\\.bam$", full.names = TRUE)
gtf_file <- "/scratch1/s2599932/pre-processing/reference-genome/gtf/Homo_sapiens.GRCh38.112.gtf"

# Run featureCounts to generate the counts matrix
counts <- featureCounts(files = bam_files, 
                        annot.ext = gtf_file,
                        isGTFAnnotationFile = TRUE, 
                        GTF.featureType = "exon",
                        GTF.attrType = "gene_id",
                        useMetaFeatures = TRUE,
                        nthreads = 10) # Adjust the number of threads as needed

# Extract the counts matrix from the output
counts_matrix <- counts$counts

# Define the output directory
output_dir <- "/scratch1/s2599932/E-MTAB-3929/counts"
dir.create(output_dir, showWarnings = FALSE)

# Save the counts matrix to a file
write.csv(counts_matrix, file = file.path(output_dir, "counts_matrix.csv"), row.names = TRUE)

# Print a message indicating successful completion
cat("Counts matrix has been successfully created and saved to", file.path(output_dir, "counts_matrix.csv"))
```











